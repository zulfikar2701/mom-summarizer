# requirements.txt
# Wheels for CUDA 12.4 are here:
--extra-index-url https://download.pytorch.org/whl/cu124

Flask==2.0.3
Werkzeug==2.0.3
Flask-Login==0.6.3
Flask-SQLAlchemy==2.5.1
SQLAlchemy==1.4.48
protobuf>=3.19.0
numpy==1.26.4
openai-whisper
whisperx
sentencepiece
transformers==4.52.3 

# Torch first – pulls the matching Triton wheel automatically
torch

# vLLM wheel that’s compiled against Torch 2.6 / CUDA 12.4
vllm==0.8.5.post1

nvidia-cudnn-cu12